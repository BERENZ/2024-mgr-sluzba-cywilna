{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d4c8f94f63ecb6f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = os.getcwd()[0:-11] + \"\\\\Cleansed_data\\\\Pre-processed_1\\\\kprm-20231115.csv\\\\kprm-20231115.csv\"\n",
    "new_df = pd.read_csv(path, sep=\";\")\n",
    "# Correcting a typo.\n",
    "new_df.rename(columns={\"date_annouced\": \"date_announced\"}, inplace=True)\n",
    "\n",
    "# Converting required level of educations to hierarchical categorical variables:\n",
    "# 1 - high school education\n",
    "# 2 - specific profile of high school education\n",
    "# 3 - higher education\n",
    "# 4 - specific profile of higher education\n",
    "# There are no ads that would require less than high school education.\n",
    "for index, row in new_df.iterrows():\n",
    "        if row[\"education\"][0:7] == \"średnie\":\n",
    "            if len(row[\"education\"]) > 10:\n",
    "                new_df.at[index, \"education\"] = 1\n",
    "            else:\n",
    "                new_df.at[index, \"education\"] = 2\n",
    "        elif row[\"education\"][0:6] == \"wyższe\":\n",
    "            if len(row[\"education\"]) > 9:\n",
    "                new_df.at[index, \"education\"] = 3\n",
    "            else:\n",
    "                new_df.at[index, \"education\"] = 4\n",
    "\n",
    "\n",
    "# Unifying the work_time column - the values there, representing a part of the full-time job, have been entered in various formats - e.g. 0.5 and 1/2.\n",
    "# new_df.loc[:, 'work_time'].unique()\n",
    "from fractions import Fraction\n",
    "\n",
    "# Lines necessary for the code below it.\n",
    "full_time_in_string_df = new_df[new_df['work_time'].str.contains(r'pełen|pełny|1|cały', na=False)]\n",
    "full_time_in_string_indexes = list(full_time_in_string_df.index)\n",
    "part_time_in_string_df = new_df[new_df['work_time'].str.contains(r'etatu|lub', na=False)]\n",
    "part_time_in_string_indexes = list(part_time_in_string_df.index)\n",
    "\n",
    "# Cleansing the work_time column.\n",
    "for index, row in new_df.iterrows():\n",
    "    try:\n",
    "        new_df.loc[index, 'work_time'] = float(new_df.loc[index, 'work_time'])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            new_df.loc[index, 'work_time'] = float(Fraction(new_df.loc[index, 'work_time']))\n",
    "        except ValueError:\n",
    "            try:\n",
    "                new_df.loc[index, 'work_time'] = float(new_df.loc[index, 'work_time'].replace(',', '.'))\n",
    "            except ValueError:\n",
    "                if new_df.loc[index, 'work_time'][9:13] == \"0,75\":\n",
    "                    new_df.loc[index, 'work_time'] = 0.75\n",
    "                elif index in full_time_in_string_indexes:\n",
    "                    new_df.loc[index, 'work_time'] = 1.0\n",
    "                elif index in part_time_in_string_indexes:\n",
    "                    try:\n",
    "                        new_df.loc[index, 'work_time'] = float(new_df.loc[index, 'work_time'][0:4].replace(',','.'))\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            new_df.loc[index, 'work_time'] = float(Fraction(new_df.loc[index, 'work_time'][0:3]))\n",
    "                        except ValueError:\n",
    "                            print(new_df.loc[index, 'work_time'])\n",
    "                elif new_df.loc[index, 'work_time'] == '¼':\n",
    "                    new_df.loc[index, 'work_time'] = 0.25\n",
    "                elif new_df.loc[index, 'work_time'] == '3/ 4':\n",
    "                    new_df.loc[index, 'work_time'] = 0.75\n",
    "                elif new_df.loc[index, 'work_time'] == '2x0,5':\n",
    "                    new_df.loc[index, 'work_time'] = 0.5\n",
    "                # Assuming that more than 1.6 * full-time job is too much to be true.\n",
    "                elif new_df.loc[index, 'work_time'] == \"zastępstwo\" or new_df.loc[index, 'work_time'] >= 1.6 or new_df.loc[index, 'work_time'] <= 0.01:\n",
    "                    new_df.loc[index, 'work_time'] = None\n",
    "\n",
    "\n",
    "# Filtering out ads with \"recruitment canceled\" without a reason given.\n",
    "result2_new_df = new_df.loc[(new_df['result1'] == 'anulowano nabór') & (~new_df[\"result2\"].isna())]\n",
    "no_reason_cancel_df = new_df.loc[(new_df['result1'] == 'anulowano nabór') & (new_df[\"result2\"].isna())]\n",
    "\n",
    "# Converting a column to lower case.\n",
    "result2_new_df.loc[:, ['result2']] = result2_new_df['result2'].str.lower()\n",
    "\n",
    "# Determining the reason for the cancellation (in the case of only \"anulowano nabór\" present in result1)\n",
    "# and assigning records to a corresponding dataframe, depending on if it's a failure or an error.\n",
    "result2_new_df_error = result2_new_df[result2_new_df['result2'].str.contains(\n",
    "    r'łędu|łąd|łędem|łędne|orekta ogłoszenia|łędnie|łędny|łędy w ogłoszeniu|rak informacji|ie uwzględniono|łędna|omyłkowo|omyłka|nie uwwzględniono|przypadkowo|dwukrotnie|podwójnie|razy wprowadzono te same|zdublowane|problem techniczny|miana treści|wymaga korekty|nie zawierało wszystkich|korekta|rak informacji|w wymaganiach|błędy|błędnie'\n",
    ")][['result2']]\n",
    "\n",
    "# The reason for leaving out first letters of w ords in some cases is that there are cases with such typos.\n",
    "result2_new_df_failure = result2_new_df[result2_new_df['result2'].str.contains(\n",
    "    r'bez wyboru kandydatki/kandydata|nie wybrano|nie zatrudniono|rak aplikacji|rak zgłoszeń|rak ofert|rak kandydatów|rak zapisów|rak zapisu kandydatów|kandydaci zrezygnowali|ikt się nie zgłosił|rak kandydatur|rak wniosków|bez zatrudnienia|kandydat zrezygnował|nie spełniały wymagań|nie wyłoniono|rezygnacji kandydata|rezygnacja|kandydat zrezygnował|zrezygnował z|nie zgłosił się|andydaci nie przybyli|zrezygnowali|braku kandydatur|kandydatka zrezygnowała|ezygnacja kandydatki|żadna oferta|rak złożonych ofert|ezygnacja kandydata|nadesłanych ofert|braku kandydatów|braku kandydatur|adna aplikacja|adnej oferty|0 ofert|brak kandydatek|raku kandydatur|rak zgłoszeń|nie zgłosił|rezygnacja|zrezygnował|ie zgłosili się|Liczba kandydatów 2, w tym 1 oferta - nie spełnia niezbędnych wymagań, 1 oferta - wycofana w trakcie trwania naboru|bark zgłoszeń|brak kandydata|braku ofert')\n",
    "][['result2']]\n",
    "\n",
    "# Applying same steps to the rest of the records.\n",
    "new_df.loc[:, ['result1']] = new_df['result1'].str.lower()\n",
    "rest_new_df_error = new_df[new_df['result1'].str.contains(\n",
    "    r'łędu|łąd|łędem|łędne|orekta ogłoszenia|łędnie|łędny|łędy w ogłoszeniu|rak informacji|ie uwzględniono|łędna|omyłkowo|omyłka|omyłką|mylnie|nie uwwzględniono|nie uwzględniono|przypadkowo|dwukrotnie|podwójnie|razy wprowadzono te same|zdublowane|problem techniczny|miana treści|wymaga korekty|nie zawierało wszystkich|korekta|rak informacji|w wymaganiach|błędy|błędnie')\n",
    "][['result1']]\n",
    "rest_new_df_failure = new_df[new_df['result1'].str.contains(\n",
    "    r'bez wyboru kandydatki/kandydata|nie wybrano|nie zatrudniono|rak aplikacji|rak zgłoszeń|rak ofert|rak kandydatów|rak zapisów|rak zapisu kandydatów|kandydaci zrezygnowali|ikt się nie zgłosił|rak kandydatur|rak wniosków|bez zatrudnienia|kandydat zrezygnował|nie spełniały wymagań|nie wyłoniono|rezygnacji kandydata|rezygnacja|kandydat zrezygnował|zrezygnował z|nie zgłosił się|andydaci nie przybyli|zrezygnowali|braku kandydatur|kandydatka zrezygnowała|ezygnacja kandydatki|żadna oferta|rak złożonych ofert|ezygnacja kandydata|nadesłanych ofert|braku kandydatów|braku kandydatur|adna aplikacja|adnej oferty|0 ofert|brak kandydatek|raku kandydatur|rak zgłoszeń|nie zgłosił|rezygnacja|zrezygnował|ie zgłosili się|Liczba kandydatów 2, w tym 1 oferta - nie spełnia niezbędnych wymagań, 1 oferta - wycofana w trakcie trwania naboru|bark zgłoszeń|brak kandydata|braku ofert')\n",
    "][['result1']]\n",
    "\n",
    "# Ads that ended successfully - a candidate has been employed.\n",
    "new_df_success = new_df[new_df['result1'].str.contains(\n",
    "    r'wyborem kandydatki/kandydata|informacja o zatrudnieniu kandydatki|zatrudnieniem|obsadzono stanowisko|wybrano kandydat')\n",
    "][['result1']]\n",
    "\n",
    "# Displaying ads that ended up without an assignment.\n",
    "assigned_ads_indexes = list(new_df_success.index) + list(rest_new_df_error.index) + list(rest_new_df_failure.index) + list(result2_new_df_failure.index) + list(result2_new_df_error.index) + list(no_reason_cancel_df.index)\n",
    "\n",
    "left_ads_df = new_df[~new_df.index.isin(assigned_ads_indexes)]\n",
    "\n",
    "# Turns out most of the left ads (1441) are irrelevant for the analysis - canceled for various reasons.\n",
    "new_df = new_df[~new_df.index.isin(list(left_ads_df.index))]\n",
    "# Excluding errors too.\n",
    "cleansed_df = new_df[new_df.index.isin(list(new_df_success.index)+list(rest_new_df_failure.index)+list(result2_new_df_failure.index))]\n",
    "\n",
    "# Assigning 1 for ads that led to employment, and 0 where there was no success.\n",
    "cleansed_df.loc[list(new_df_success.index), 'result1'] = 1\n",
    "cleansed_df.loc[list(result2_new_df_failure.index)+list(rest_new_df_failure.index), 'result1'] = 0\n",
    "\n",
    "# ASSIGNING POSITION LEVEL CATEGORIES\n",
    "\n",
    "# Splitting job positions into categories, just like it's been done with 'failure' and 'success'.\n",
    "assistent_df = cleansed_df[cleansed_df['job_title'].str.contains(r'asystent|pomocnik', case=False)][['job_title']]\n",
    "junior_df = cleansed_df[cleansed_df['job_title'].str.contains(r'młodszy|mlodszy', case=False)][['job_title']]\n",
    "senior_df = cleansed_df[cleansed_df['job_title'].str.contains(r'starszy', case=False)][['job_title']]\n",
    "director_df = cleansed_df[cleansed_df['job_title'].str.contains(r'dyrektor|kierownik|kapitan|naczelnik', case=False)][['job_title']]\n",
    "# 'Główny' is translated as 'head' or 'main'.\n",
    "head_df = cleansed_df[cleansed_df['job_title'].str.contains(r'główny|glowny', case=False)][['job_title']]\n",
    "\n",
    "# Separating \"specjalista\" and \"ekspert\" from \"młodszy/starszy specjalista/ekspert\",\n",
    "# so that there are no duplicates with junior_df and senior_df.\n",
    "expert_df = (\n",
    "    cleansed_df[\n",
    "        (cleansed_df['job_title'].str.contains(r'ekspert|specjalista', case=False) == True) &\n",
    "        (cleansed_df['job_title'].str.contains(r'młodszy|mlodszy|starszy', case=False) == False)]\n",
    "    [['job_title']]\n",
    ")\n",
    "\n",
    "# Categorizing ads that ended up without an assignment to the previous categories\n",
    "# (regular positions, between junior and senior).\n",
    "position_categories_indexes = (\n",
    "        list(junior_df.index) + list(senior_df.index) + list(director_df.index) + list(expert_df.index) +\n",
    "        list(assistent_df.index) + list(head_df.index)\n",
    ")\n",
    "mid_df = cleansed_df[~cleansed_df.index.isin(position_categories_indexes)]\n",
    "\n",
    "# Assigning cleansed categories to a new column - specific categories might turn out useful later on,\n",
    "# so I don't want to dispose of this information.\n",
    "\n",
    "# Creating a new column by copying the existing one.\n",
    "cleansed_df[\"job_position_category\"] = cleansed_df[\"job_title\"]\n",
    "# Changing the values of the column so that it represents job level categories.\n",
    "cleansed_df.loc[list(junior_df.index), 'job_position_category'] = 'junior'\n",
    "cleansed_df.loc[list(senior_df.index), 'job_position_category'] = 'senior'\n",
    "cleansed_df.loc[list(assistent_df.index), 'job_position_category'] = 'assistent'\n",
    "cleansed_df.loc[list(head_df.index), 'job_position_category'] = 'head/main'\n",
    "cleansed_df.loc[list(director_df.index), 'job_position_category'] = 'director/manager'\n",
    "cleansed_df.loc[list(expert_df.index), 'job_position_category'] = 'expert'\n",
    "cleansed_df.loc[list(mid_df.index), 'job_position_category'] = 'mid'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8b2c2e83409447",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# DETERMINING THE FIELD OF THE JOB\n",
    "\n",
    "vet_df = (\n",
    "    cleansed_df[\n",
    "        cleansed_df['job_title'].str.contains('weteryn.+', regex=True, case=False)\n",
    "    ]\n",
    "[['job_title']]\n",
    ")\n",
    "IT_n_maths_df = (\n",
    "    cleansed_df[\n",
    "        cleansed_df['job_title'].str.contains('.nformaty.+|IT|program.+|statyst.+|matemat.+|anali.+', regex=True, case=True)\n",
    "    ]\n",
    "    [['job_title']]\n",
    ")\n",
    "# Note: 'veterinary inspector' or 'pharmacy inspector' are categorized as 'vet' and 'pharmacy/chemistry', respectively.\n",
    "law_df = (\n",
    "    cleansed_df[\n",
    "        (cleansed_df['job_title'].str.contains(\n",
    "            'radca|prawnik|kontroler|skarb.+|prawny|wizytator|aplikant|oskarżyciel|aplikant|referendarz|podreferendarz|księgow.+|inspektor',\n",
    "            regex=True, case=False)==True) & \n",
    "        (cleansed_df['job_title'].str.contains('weteryn.+|farmac.+|aptek.+|lecznic.+|laborator.+', regex=True, case=False)==False)\n",
    "    ]\n",
    "    [['job_title']]\n",
    ")\n",
    "pharmacy_n_chemistry_df = (\n",
    "    cleansed_df[\n",
    "        cleansed_df['job_title'].str.contains('farmac.+|aptek.+|lecznic.+|laborator.+', regex=True, case=False)\n",
    "    ]\n",
    "    [['job_title']]\n",
    ")\n",
    "# Bossman, captain, port, etc.\n",
    "water_df = (\n",
    "    cleansed_df[\n",
    "        cleansed_df['job_title'].str.contains('bossman.+|kapitan|bosman.+|port|wybrzeż.+', regex=True, case=False)\n",
    "    ]\n",
    "    [['job_title']]\n",
    ")\n",
    "tech_n_construction_df = (\n",
    "    cleansed_df[\n",
    "        cleansed_df['job_title'].str.contains('technik|techniczny|górni.+|budowl.+', regex=True, case=False)\n",
    "    ]\n",
    "    [['job_title']]\n",
    ")\n",
    "documents_df = (\n",
    "    cleansed_df[\n",
    "        (cleansed_df['job_title'].str.contains('referent|legalizator|archiwista', case=False)==True) &\n",
    "        (cleansed_df['job_title'].str.contains('.nformaty.+|IT|program.+|statyst.+|matemat.+|anali.+', regex=True, case=False)==False)\n",
    "    ]\n",
    "    [['job_title']]\n",
    ")\n",
    "# Manager-like job positions that haven't been categorized in any of the previous fields.\n",
    "manager_df = (\n",
    "    cleansed_df[\n",
    "        (cleansed_df['job_title'].str.contains(r'kierownik|dyrektor|naczelnik.+', regex=True, case=False)==True) &\n",
    "        (cleansed_df['job_title'].str.contains('weteryn.+|informat.+|port.+|techni.+|górni.+|budowl.+', regex=True, case=False)==False)\n",
    "    ]\n",
    "    [['job_title']]\n",
    ")\n",
    "\n",
    "\n",
    "# Indices of all obtained matches from the above criteria stored in one list.\n",
    "job_field_indexes = (\n",
    "        list(documents_df.index) + list(tech_n_construction_df.index) + list(water_df.index) + list(pharmacy_n_chemistry_df.index) +\n",
    "        list(manager_df.index) + list(law_df.index) + list(IT_n_maths_df.index) + list(vet_df.index)\n",
    ")\n",
    "\n",
    "# Fields that haven't been categorized by the above criteria.\n",
    "left_job_fields_df = cleansed_df[~cleansed_df.index.isin(job_field_indexes)]\n",
    "\n",
    "\n",
    "# Most of the fields can be categorized simply by the 'job_title' column, however, \n",
    "# without including the department name in the 'work_place2' or 'institution' columns, \n",
    "# around 30% of ads are left without a specific category.\n",
    "\n",
    "# Browsing through ads that haven't been categorized, to avoid double categorization.\n",
    "environment_protection_df = (\n",
    "    left_job_fields_df[\n",
    "        (cleansed_df['institution'].str.contains('środowisk.+|leśn.+|las.+|roślin.+|nasiennictwa', regex=True, case=False))|\n",
    "        (cleansed_df['work_place2'].str.contains('środowisk.+|leśn.+|las.+|roślin.+|nasiennictwa', regex=True, case=False))\n",
    "    ]\n",
    ")\n",
    "# Working for the following entities: police, firefighters, military, border guards.\n",
    "uniformed_services_df = (\n",
    "    left_job_fields_df[\n",
    "        (cleansed_df['institution'].str.contains('polic.+|straż.+|wojsk.+|żołnier.+', regex=True, case=False))|\n",
    "        (cleansed_df['work_place2'].str.contains('polic.+|straż.+|wojsk.+|żołnier.+', regex=True, case=False))\n",
    "    ]\n",
    ")\n",
    "uncategorized_med_df = (\n",
    "    left_job_fields_df[\n",
    "        (cleansed_df['institution'].str.contains('med.+|farmaceu.+|chemi.+|sanitar.+', regex=True, case=False))|\n",
    "        (cleansed_df['work_place2'].str.contains('med.+|farmaceu.+|chemi.+|sanitar.+', regex=True, case=False))\n",
    "    ]\n",
    ")\n",
    "uncategorized_tech_n_construction_df = (\n",
    "    left_job_fields_df[\n",
    "        (cleansed_df['institution'].str.contains('budowl.+|górni.+|techn.+|drog.+|dróg|autostrad.+|infrastruk.+', regex=True, case=False))|\n",
    "        (cleansed_df['work_place2'].str.contains('budowl.+|górni.+|techn.+|drog.+|dróg|autostrad.+|infrastruk.+', regex=True, case=False))\n",
    "    ]\n",
    ")\n",
    "uncategorized_IT_n_statistics_df = (\n",
    "    left_job_fields_df[\n",
    "        (cleansed_df['institution'].str.contains('informat.+|architektury danych|statyst.+|analiz.+', regex=True, case=False)==True)|\n",
    "        (cleansed_df['work_place2'].str.contains('informat.+|architektury danych|statyst.+|analiz.+', regex=True, case=False)==True)&\n",
    "        (cleansed_df['work_place2'].str.contains('teleinfromatyk.+', regex=True, case=False)==False)\n",
    "        # ^some jobs at the ICT department are not associated with IT at all.\n",
    "    ]\n",
    ")\n",
    "uncategorized_law_df = (\n",
    "    left_job_fields_df[\n",
    "        (cleansed_df['institution'].str.contains('prawn.+|księgow.+', regex=True, case=False))|\n",
    "        (cleansed_df['work_place2'].str.contains('prawn.+|księgow.+', regex=True, case=False))\n",
    "    ]\n",
    ")\n",
    "uncategorized_water_df = (\n",
    "    left_job_fields_df[\n",
    "        (cleansed_df['institution'].str.contains('morsk.+', regex=True, case=False))|\n",
    "        (cleansed_df['work_place2'].str.contains('morsk.+', regex=True, case=False))\n",
    "    ]\n",
    ")\n",
    "uncategorized_vet_df = (\n",
    "    left_job_fields_df[\n",
    "        (cleansed_df['institution'].str.contains('weteryn.+', regex=True, case=False))|\n",
    "        (cleansed_df['work_place2'].str.contains('weteryn.+', regex=True, case=False))\n",
    "    ]    \n",
    ")\n",
    "\n",
    "# Indices of ads that are still left without a category.\n",
    "# They are going to have 'other' category assigned.\n",
    "newly_categorized_ads = (\n",
    "    list(uncategorized_law_df.index) + list(uncategorized_IT_n_statistics_df.index) + list(uncategorized_tech_n_construction_df.index) + list(uncategorized_med_df.index) +\n",
    "    list(uniformed_services_df.index) + list(uncategorized_law_df.index) + list(environment_protection_df.index) + list(uncategorized_water_df) + list(uncategorized_vet_df.index)\n",
    ")\n",
    "other_job_fields_df = left_job_fields_df[~left_job_fields_df.index.isin(newly_categorized_ads)]\n",
    "\n",
    "# Again, it is undesired to drop the job_title column, so I'm creating a new one.\n",
    "cleansed_df[\"job_field\"] = cleansed_df[\"job_title\"]\n",
    "cleansed_df.loc[list(documents_df.index), 'job_field'] = 'documents'\n",
    "cleansed_df.loc[list(tech_n_construction_df.index), 'job_field'] = 'tech/construction'\n",
    "cleansed_df.loc[list(uncategorized_tech_n_construction_df.index), 'job_field'] = 'tech/construction'\n",
    "cleansed_df.loc[list(water_df.index), 'job_field'] = 'water'\n",
    "cleansed_df.loc[list(uncategorized_water_df.index), 'job_field'] = 'water'\n",
    "cleansed_df.loc[list(pharmacy_n_chemistry_df.index), 'job_field'] = 'pharmacy/chemistry'\n",
    "cleansed_df.loc[list(uncategorized_med_df.index), 'job_field'] = 'pharmacy/chemistry'\n",
    "cleansed_df.loc[list(manager_df.index), 'job_field'] = 'other_manager'\n",
    "cleansed_df.loc[list(law_df.index), 'job_field'] = 'law'\n",
    "cleansed_df.loc[list(uncategorized_law_df.index), 'job_field'] = 'law'\n",
    "cleansed_df.loc[list(IT_n_maths_df.index), 'job_field'] = 'IT/statistics'\n",
    "cleansed_df.loc[list(uncategorized_IT_n_statistics_df.index), 'job_field'] = 'IT/statistics'\n",
    "cleansed_df.loc[list(vet_df.index), 'job_field'] = 'vet'\n",
    "cleansed_df.loc[list(uncategorized_vet_df.index), 'job_field'] = 'vet'\n",
    "cleansed_df.loc[list(environment_protection_df.index), 'job_field'] = 'environment'\n",
    "cleansed_df.loc[list(uniformed_services_df.index), 'job_field'] = 'uniformed services'\n",
    "cleansed_df.loc[list(other_job_fields_df.index), 'job_field'] = 'other'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f71ed38058fe6552",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formatting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26007ec14bb9cf1e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns.\n",
    "cleansed_df.drop(columns=['result2', 'date_documents', 'date_result', 'date_valid'], inplace=True)\n",
    "\n",
    "# Reindexing and renaming columns so that the order is more intuitive.\n",
    "cleansed_df = cleansed_df.reindex(columns=['job_id', 'result1', 'job_field', 'job_position_category', 'job_title', 'education', 'work_time', 'vacancies', 'salary', 'city', 'institution', 'work_place1', 'work_place2', 'address', 'responsibilities', 'requirements1', 'requirements2', 'date_announced', 'views'])\n",
    "\n",
    "cleansed_df.rename({'job_id': 'ad_id', 'result1': 'result', 'job_field': 'job_field', 'job_position_category': 'position_category', 'job_title': 'position', 'education': 'education_level', 'work_time': 'work_time', 'vacancies': 'vacancies', 'salary': 'salary', 'city': 'city', 'institution': 'institution', 'address': 'institution_address', 'work_place1': 'workplace', 'work_place2': 'department', 'responsibilities': 'responsibilities', 'requirements1': 'requirements', 'requirements2': 'nice_to_have', 'date_announced': 'date_announced', 'views': 'views'}, axis='columns', inplace=True)\n",
    "\n",
    "path = os.getcwd()[0:-11] + 'Cleansed_data\\\\Cleaned_2\\\\'\n",
    "cleansed_df.to_csv(path + 'cleaned_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47a2939f34c80aac",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
